import os
import sys
import pandas as pd
import psycopg2
from psycopg2 import sql
from psycopg2.extras import RealDictCursor
from dotenv import load_dotenv
from datetime import datetime
import logging

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('excel_import.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Database configuration
DATABASE_HOST = os.getenv("DATABASE_HOST", "localhost")
DATABASE_PORT = int(os.getenv("DATABASE_PORT", "5432"))
DATABASE_NAME = os.getenv("DATABASE_NAME", "power_bi_bot")
DATABASE_USER = os.getenv("DATABASE_USER", "bot_user")
DATABASE_PASSWORD = os.getenv("DATABASE_PASSWORD", "bot_password")

# Excel file path
EXCEL_FILE_PATH = "Data_DM (3).xlsx"

# Column mapping from Russian (Excel) to English (Database)
# This mapping will need to be adjusted based on actual Excel column names
COLUMN_MAPPINGS = {
    'P1': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '–†–æ–ª—å': 'edu_role',
        '–¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã  –∂–∞–ª–æ–±–∞': 'edu_problem',
        '–û–ø–∏—Å–∞–Ω–∏–µ –∂–∞–ª–æ–±–∞': 'edu_describtion',
        '–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã_–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞': 'edu_action',
        '–°—Ç–∞—Ç—É—Å_–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞': 'edu_contact'
    },
    'P2': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '–†–æ–ª—å': 'edu_role',
        '–°—Ñ–µ—Ä–∞ –∏–¥–µ–∏': 'edu_sphere',
        '–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç': 'edu_result',
        '–û–ø–∏—Å–∞–Ω–∏–µ –∏–¥–µ–∏': 'edu_describtion',
        '–ê–≤—Ç–æ—Ä –∏–¥–µ–∏': 'edu_author',
        '–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_action',
        '–°—Ç–∞—Ç—É—Å_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_contact'
    },
    'P3': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        'üôÇ\xa0–≠–º–æ—Ü–∏—è–ª—ã“õ –∂–∞“ì–¥–∞–π / –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ': 'edu_emotional_state',
        'ü§ù\xa0“ö–∞“õ—Ç—ã“ì—ã—Å—Ç–∞—Ä –∂”ô–Ω–µ “õ–∞—Ä—ã–º-“õ–∞—Ç—ã–Ω–∞—Å—Ç–∞—Ä / –ö–æ–Ω—Ñ–ª–∏–∫—Ç—ã –∏ –≤–∑–∞–∏–º–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è': 'edu_conflicts_relations',
        'üö´\xa0–ë—É–ª–ª–∏–Ω–≥ / –∫–∏–±–µ—Ä–±—É–ª–ª–∏–Ω–≥': 'edu_bullying_cyberbullying',
        'üìñ\xa0–û“õ—É–¥–∞“ì—ã –º”ô—Å–µ–ª–µ–ª–µ—Ä / –ü—Ä–æ–±–ª–µ–º—ã –≤ –æ–±—É—á–µ–Ω–∏–∏': 'edu_learning_problems',
        '‚ö†Ô∏è\xa0–î–∞“ì–¥–∞—Ä—ã—Å—Ç—ã“õ –∂–∞“ì–¥–∞–π–ª–∞—Ä / –ö—Ä–∏–∑–∏—Å–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏': 'edu_crisis_situations',
        'üí¨\xa0–ü—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∞–ª—ã“õ ”ô“£–≥—ñ–º–µ / –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è / –ü—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –±–µ—Å–µ–¥–∞ / –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è': 'edu_preventive_consultation',
        'üìå\xa0–ë–∞—Å“õ–∞ / –ü—Ä–æ—á–µ–µ': 'edu_other',
        '–ë–∞—Ä–ª—ã“ì—ã_–ø—Å–∏—Ö–æ–ª–æ–≥': 'edu_total_psychologist',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_contact'
    },
    'Q1': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '–†–æ–ª—å': 'edu_role',
        '–¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ': 'edu_problem',
        '–°—ã–Ω—ã–ø_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ': 'edu_grate',
        '–õ–∏—Ç–µ—Ä —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ': 'edu_litter',
        '–ü—Ä–µ–¥–º–µ—Ç_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ': 'edu_subject',
        '–î–∞—Ç–∞_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ': 'edu_problem_date',
        '–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ': 'edu_action',
        '–°—Ç–∞—Ç—É—Å_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ': 'edu_contact'
    },
    'Q2': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '–†–æ–ª—å': 'edu_role',
        '–¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–µ–¥–º–µ—Ç': 'edu_problem',
        '–ü—Ä–µ–¥–º–µ—Ç_–ø—Ä–µ–¥–º–µ—Ç': 'edu_subject',
        '–°—ã–Ω—ã–ø –ø—Ä–µ–¥–º–µ—Ç': 'edu_grate',
        '–õ–∏—Ç–µ—Ä –ø—Ä–µ–¥–º–µ—Ç': 'edu_litter',
        '–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã_–ø—Ä–µ–¥–º–µ—Ç': 'edu_action',
        '–°—Ç–∞—Ç—É—Å_–ø—Ä–µ–¥–º–µ—Ç': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–ø—Ä–µ–¥–º–µ—Ç': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–ø—Ä–µ–¥–º–µ—Ç': 'edu_contact'
    },
    'Q3': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '–†–æ–ª—å': 'edu_role',
        '–¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞': 'edu_problem',
        '–§–ò–û —É—á–∞—â–∏—Ö—Å—è_–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞': 'edu_full_name',
        '–°—ã–Ω—ã–ø –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞': 'edu_grate',
        '–õ–∏—Ç–µ—Ä –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞': 'edu_litter',
        '–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã_–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞': 'edu_action',
        '–°—Ç–∞—Ç—É—Å_–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞': 'edu_contact'
    },
    'Q4': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '–†–æ–ª—å': 'edu_role',
        '–ù–æ–º–µ—Ä –∫–∞–±–∏–Ω–µ—Ç–∞': 'edu_problem',  # Mapping room number to problem field
        '–¢–∏–ø —Å–±–æ—è': None,  # Skip this - no good mapping
        '–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_action',
        '–°—Ç–∞—Ç—É—Å_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_contact'
    },
    'Q5': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        'üë• –ë–∞—Ä–ª—ã“ì—ã / –í—Å–µ–≥–æ —É—á–∏—Ç–µ–ª–µ–π': 'edu_total_teachers',
        'ü§í –ê—É—ã—Ä“ì–∞–Ω—ã–Ω–∞ –±–∞–π–ª–∞–Ω—ã—Å—Ç—ã / –ü–æ –±–æ–ª–µ–∑–Ω–∏': 'edu_illness',
        '‚úàÔ∏è –Ü—Å—Å–∞–ø–∞—Ä / –ö–æ–º–∞–Ω–¥–∏—Ä–æ–≤–∫–∞': 'edu_business_trip',
        'üè† –ñ–µ–∫–µ —Å–µ–±–µ–ø—Ç–µ—Ä / –õ–∏—á–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã': 'edu_personal_reasons',
        'üéì –ë—ñ–ª—ñ–∫—Ç—ñ–ª—ñ–∫—Ç—ñ –∞—Ä—Ç—Ç—ã—Ä—É / –ü–æ–≤—ã—à–µ–Ω–∏–µ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏': 'edu_professional_development',
        'üìå –ë–∞—Å“õ–∞ / –ü—Ä–æ—á–µ–µ': 'edu_other',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_contact'
    },
    'S1': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '—Ä–æ–ª—å': 'edu_role',
        '–û—Å–º–æ—Ç—Ä–µ–Ω–æ –∫–∞–±–∏–Ω–µ—Ç–æ–≤': 'edu_class_num',
        '–≠—Ç–∞–∂': 'edu_floor',
        '–ö–∞–±–∏–Ω–µ—Ç': 'edu_classroom',
        '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ': 'edu_problem',
        '–°–æ—Å—Ç–æ—è–Ω–∏–µ –∫–∞–±–∏–Ω–µ—Ç–∞': 'edu_condition',
        '–î–µ–π—Å—Ç–≤–∏—è': 'edu_action',
        '–°—Ç–∞—Ç—É—Å': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–ö–µ—Ä—ñ –±–∞–π–ª–∞–Ω—ã—Å': 'edu_contact'
    },
    'S2': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '–†–æ–ª—å': 'edu_role',
        '–û—Å–º–æ—Ç—Ä–µ–Ω–æ –ª–æ–∫–∞—Ü–∏–π': 'edu_loc_num',
        '–õ–æ–∫–∞—Ü–∏—è_–ß–®': 'edu_location',
        '–≠—Ç–∞–∂_–ß–®': 'edu_floor',
        '–ú–µ—Å—Ç–æ_–ß–®': 'edu_place',
        '–¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã_–ß–®': 'edu_problem',
        '–°–æ—Å—Ç–æ—è–Ω–∏–µ_–ß–®': 'edu_condition',
        '–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã_–ß–®': 'edu_action',
        '–°—Ç–∞—Ç—É—Å_–ß–®': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–ß–®': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö_–ß–®': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–ß–®': 'edu_contact'
    },
    'S3': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '–†–æ–ª—å': 'edu_role',
        '–û—Å–º–æ—Ç—Ä–µ–Ω–æ –ª–æ–∫–∞—Ü–∏–π': 'edu_loc_num',
        '–õ–æ–∫–∞—Ü–∏—è_–¢–†': 'edu_location',
        '–≠—Ç–∞–∂_–¢–†': 'edu_floor',
        '–ú–µ—Å—Ç–æ_–¢–†': 'edu_place',
        '–¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã_–¢–†': 'edu_problem',
        '–°–æ—Å—Ç–æ—è–Ω–∏–µ_–¢–†': 'edu_condition',
        '–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã_–¢–†': 'edu_action',
        '–°—Ç–∞—Ç—É—Å_–¢–†': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–¢–†': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö_–¢–†': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–¢–†': 'edu_contact'
    },
    'S4': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '—Ä–æ–ª—å': 'edu_role',
        '–¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã': 'edu_problem',
        '–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ä–∏—Å–∫–∞': 'edu_condition',
        '–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã': 'edu_action',
        '–°—Ç–∞—Ç—É—Å': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏': 'edu_contact'
    },
    'S5': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '–†–æ–ª—å': 'edu_role',
        '–ò–Ω—Ü–∏–¥–µ–Ω—Ç': 'edu_incident',
        '–û–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Ü–∏–¥–µ–Ω—Ç': 'edu_describtion',
        '–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã_–∏–Ω—Ü–∏–¥–µ–Ω—Ç': 'edu_action',
        '–°—Ç–∞—Ç—É—Å_–∏–Ω—Ü–∏–¥–µ–Ω—Ç': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–∏–Ω—Ü–∏–¥–µ–Ω—Ç': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–∏–Ω—Ü–∏–¥–µ–Ω—Ç': 'edu_contact'
    },
    'S6': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '–†–æ–ª—å': 'edu_role',
        '–û—Ö—Ä–∞–Ω–∞': 'edu_security',
        '–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã_–æ—Ö—Ä–∞–Ω–∞': 'edu_action',
        '–°—Ç–∞—Ç—É—Å_–æ—Ö—Ä–∞–Ω–∞': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–æ—Ö—Ä–∞–Ω–∞': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–æ—Ö—Ä–∞–Ω–∞': 'edu_contact'
    },
    'S7': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        '–†–æ–ª—å': 'edu_role',
        '–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_problem',
        '–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_action',
        '–°—Ç–∞—Ç—É—Å_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_status',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_contact'
    },
    'S8': {
        'ID': 'id',
        '–ú–µ–∫—Ç–µ–ø': 'edu_school',
        '–î–∞—Ç–∞': 'edu_date',
        '–í—Ä–µ–º—è –æ–±—Ö–æ–¥–∞': 'edu_time',
        'üçΩ –ê—Å “õ–æ—Ä—ã—Ç—É –∂“Ø–π–µ—Å—ñ / –ñ–ö–¢ (–ø–∏—â–µ–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞)': 'edu_digestive_system',
        '–¢“±–º–∞—É / –û–†–í–ò –∏ –ø—Ä–æ—Å—Ç—É–¥–Ω—ã–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è': 'edu_cold_flu',
        'ü§ï –ñ–∞—Ä–∞“õ–∞—Ç—Ç–∞—Ä / –¢—Ä–∞–≤–º—ã': 'edu_injuries',
        'üå∏ –ê–ª–ª–µ—Ä–≥–∏—è–ª—ã“õ —Ä–µ–∞–∫—Ü–∏—è–ª–∞—Ä / –ê–ª–ª–µ—Ä–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ–∞–∫—Ü–∏–∏': 'edu_allergic_reactions',
        'üß† –ù–µ–≤—Ä–æ–ª–æ–≥–∏—è–ª—ã“õ –∂”ô–Ω–µ –∂–∞–ª–ø—ã –∂–∞“ì–¥–∞–π / –ù–µ–≤—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∏ –æ–±—â–µ–µ —Å–∞–º–æ—á—É–≤—Å—Ç–≤–∏–µ': 'edu_neurological_general',
        '‚ôªÔ∏è –°–æ–∑—ã–ª–º–∞–ª—ã –∞—É—Ä—É–ª–∞—Ä–¥—ã“£ –∞—Å“õ—ã–Ω—É—ã / –û–±–æ—Å—Ç—Ä–µ–Ω–∏–µ —Ö—Ä–æ–Ω–∏—á–µ—Å–∫–∏—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π': 'edu_chronic_diseases',
        'üìå –ë–∞—Å“õ–∞ / –ü—Ä–æ—á–µ–µ': 'edu_other',
        '–ë–∞—Ä–ª—ã“ì—ã_–º–µ–¥–∏—Ü–∏–Ω–∞': 'edu_total_medical',
        '–§–æ—Ç–æ/—Å—Å—ã–ª–∫–∞_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_photo',
        '–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö': 'edu_data_from',
        '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ —Å–ª–æ–º–∞–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å)': 'edu_add_inf',
        '–∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏_–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 'edu_contact'
    }
}

def get_database_connection():
    """Establish connection to PostgreSQL database."""
    try:
        connection = psycopg2.connect(
            host=DATABASE_HOST,
            port=DATABASE_PORT,
            database=DATABASE_NAME,
            user=DATABASE_USER,
            password=DATABASE_PASSWORD
        )
        return connection
    except Exception as e:
        logger.error(f"Error connecting to database: {e}")
        raise

def test_database_connection():
    """Test database connection and show basic info."""
    try:
        conn = get_database_connection()
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        
        # Test connection
        cursor.execute("SELECT version();")
        version = cursor.fetchone()
        if version:
            logger.info(f"PostgreSQL version: {version['version']}")
        else:
            logger.info("Connected to PostgreSQL database")
        
        # Check if tables exist
        cursor.execute("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'dbo' 
            AND table_name IN ('p1', 'p2', 'p3', 'q1', 'q2', 'q3', 'q4', 'q5', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8')
            ORDER BY table_name;
        """)
        
        tables = cursor.fetchall()
        table_names = [table['table_name'] for table in tables]
        logger.info(f"Found tables: {table_names}")
        
        cursor.close()
        conn.close()
        
        return True, table_names
    except Exception as e:
        logger.error(f"Database connection test failed: {e}")
        return False, []

def read_excel_file(file_path):
    """Read Excel file and return dictionary of DataFrames for each sheet."""
    try:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Excel file not found: {file_path}")
        
        # Read all sheets
        excel_data = pd.read_excel(file_path, sheet_name=None, engine='openpyxl')
        
        # Filter only the sheets we need
        target_sheets = ['P1', 'P2', 'P3', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8']
        filtered_data = {}
        
        for sheet_name in target_sheets:
            if sheet_name in excel_data:
                df = excel_data[sheet_name]
                if not df.empty:
                    filtered_data[sheet_name] = df
                    logger.info(f"Sheet {sheet_name}: {len(df)} rows, {len(df.columns)} columns")
                else:
                    logger.warning(f"Sheet {sheet_name} is empty")
            else:
                logger.warning(f"Sheet {sheet_name} not found in Excel file")
        
        return filtered_data
    except Exception as e:
        logger.error(f"Error reading Excel file: {e}")
        raise

def map_columns(df, sheet_name):
    """Map Russian column names to English database column names."""
    if sheet_name not in COLUMN_MAPPINGS:
        logger.warning(f"No column mapping found for sheet {sheet_name}")
        return df
    
    mapping = COLUMN_MAPPINGS[sheet_name]
    
    # Create a mapping dictionary for actual columns that exist in the DataFrame
    actual_mapping = {}
    for russian_col, english_col in mapping.items():
        if english_col is None:  # Skip columns that have no database equivalent
            continue
        if russian_col in df.columns:
            actual_mapping[russian_col] = english_col
        else:
            # Try to find similar column names (case insensitive, strip whitespace)
            for col in df.columns:
                if str(col).strip().lower() == russian_col.lower():
                    actual_mapping[col] = english_col
                    break
    
    # Debug: Print column mapping details for P3
    if sheet_name == 'P3':
        logger.info(f"P3 Debug - Excel columns: {list(df.columns)}")
        logger.info(f"P3 Debug - Mapping attempted: {list(mapping.keys())}")
        logger.info(f"P3 Debug - Successful mappings: {actual_mapping}")
        
        # Check specific emoji columns
        emoji_cols = [col for col in df.columns if any(emoji in str(col) for emoji in ['üôÇ', 'ü§ù', 'üö´', 'üìñ', '‚ö†Ô∏è', 'üí¨', 'üìå'])]
        logger.info(f"P3 Debug - Emoji columns found: {emoji_cols}")
        
        for col in emoji_cols:
            if col in df.columns:
                logger.info(f"P3 Debug - Column '{col}' sample data: {df[col].head(3).tolist()}")
    
    # Rename columns
    df_mapped = df.rename(columns=actual_mapping)
    
    # Add default values for missing columns
    if 'edu_data_from' not in df_mapped.columns:
        df_mapped['edu_data_from'] = 'Excel Import'
    
    logger.info(f"Sheet {sheet_name}: Mapped {len(actual_mapping)} columns")
    logger.debug(f"Column mapping for {sheet_name}: {actual_mapping}")
    
    return df_mapped

def clean_data(df):
    """Clean and prepare data for database insertion."""
    import datetime
    
    # Make a copy to avoid modifying the original
    df = df.copy()
    
    # Convert datetime columns
    for col in df.columns:
        if 'date' in col.lower():
            if df[col].dtype == 'object' or 'datetime' in str(df[col].dtype):
                # Check if values are already date objects
                sample_non_null = df[col].dropna()
                if len(sample_non_null) > 0 and isinstance(sample_non_null.iloc[0], datetime.date):
                    # Already date objects, just replace NaN with None
                    df[col] = df[col].where(pd.notnull(df[col]), None)
                else:
                    df[col] = pd.to_datetime(df[col], errors='coerce').dt.date
                    # Replace NaT with None
                    df[col] = df[col].where(pd.notnull(df[col]), None)
        elif 'time' in col.lower() and col != 'created_at':
            # Check if values are already time objects
            sample_non_null = df[col].dropna()
            if len(sample_non_null) > 0:
                first_val = sample_non_null.iloc[0]
                if isinstance(first_val, datetime.time):  # Already a time object
                    # Just replace NaT/NaN with None
                    df[col] = df[col].where(pd.notnull(df[col]), None)
                else:
                    # Convert to time
                    if df[col].dtype == 'object' or 'datetime' in str(df[col].dtype):
                        df[col] = pd.to_datetime(df[col], errors='coerce').dt.time
                        # Replace NaT with None
                        df[col] = df[col].where(pd.notnull(df[col]), None)
    
    # Replace all remaining NaN/NaT values with None
    df = df.where(pd.notnull(df), None)
    
    return df

def insert_data_to_table(conn, table_name, df):
    """Insert DataFrame data into specified table."""
    if df.empty:
        logger.info(f"No data to insert for table {table_name}")
        return 0
    
    try:
        cursor = conn.cursor()
        
        # Get table columns from database
        cursor.execute(sql.SQL("""
            SELECT column_name 
            FROM information_schema.columns 
            WHERE table_schema = 'dbo' 
            AND table_name = %s 
            AND column_name != 'id' 
            AND column_name != 'created_at'
            ORDER BY ordinal_position;
        """), [table_name])
        
        db_columns = [row[0] for row in cursor.fetchall()]
        
        # Filter DataFrame columns to match database columns
        available_columns = [col for col in db_columns if col in df.columns]
        
        if not available_columns:
            logger.warning(f"No matching columns found for table {table_name}")
            return 0
        
        # Prepare data for insertion
        df_filtered = df[available_columns].copy()
        df_filtered = clean_data(df_filtered)
        
        # Additional cleaning for problematic values
        for col in df_filtered.columns:
            try:
                if df_filtered[col].dtype == 'object':
                    # Replace any string representations of NaT or NaN
                    df_filtered[col] = df_filtered[col].replace(['NaT', 'NaN', 'nat', 'nan'], None)
            except Exception as e:
                logger.debug(f"Could not process column {col}: {e}")
                continue
        
        logger.debug(f"Data types for {table_name}: {df_filtered.dtypes.to_dict()}")
        logger.debug(f"Sample data for {table_name}: {df_filtered.head(2).to_dict()}")
        
        # Create INSERT query
        columns_sql = sql.SQL(', ').join(sql.Identifier(col) for col in available_columns)
        placeholders = sql.SQL(', ').join(sql.Placeholder() * len(available_columns))
        
        insert_query = sql.SQL("""
            INSERT INTO dbo.{table} ({columns}) 
            VALUES ({placeholders})
        """).format(
            table=sql.Identifier(table_name),
            columns=columns_sql,
            placeholders=placeholders
        )
        
        # Convert DataFrame to list of tuples, ensuring no pandas objects
        data_tuples = []
        for _, row in df_filtered.iterrows():
            row_tuple = []
            for value in row:
                if pd.isna(value) or str(value) in ['NaT', 'NaN', 'nat', 'nan']:
                    row_tuple.append(None)
                else:
                    # Truncate text that's too long for database fields
                    if isinstance(value, str) and len(value) > 500:
                        logger.warning(f"Truncating long text in {table_name}: {value[:50]}...")
                        value = value[:500]
                    row_tuple.append(value)
            data_tuples.append(tuple(row_tuple))
        
        # Execute batch insert
        cursor.executemany(insert_query, data_tuples)
        rows_inserted = cursor.rowcount
        
        conn.commit()
        cursor.close()
        
        logger.info(f"Successfully inserted {rows_inserted} rows into table {table_name}")
        return rows_inserted
        
    except Exception as e:
        logger.error(f"Error inserting data into table {table_name}: {e}")
        conn.rollback()
        raise

def main():
    """Main function to execute the Excel to PostgreSQL import."""
    logger.info("Starting Excel to PostgreSQL import process")
    
    # Test database connection
    logger.info("Testing database connection...")
    connection_ok, existing_tables = test_database_connection()
    
    if not connection_ok:
        logger.error("Database connection failed. Exiting.")
        sys.exit(1)
    
    # Read Excel file
    logger.info(f"Reading Excel file: {EXCEL_FILE_PATH}")
    try:
        excel_data = read_excel_file(EXCEL_FILE_PATH)
    except Exception as e:
        logger.error(f"Failed to read Excel file: {e}")
        sys.exit(1)
    
    if not excel_data:
        logger.error("No valid sheets found in Excel file")
        sys.exit(1)
    
    # Process each sheet
    total_inserted = 0
    conn = get_database_connection()
    
    try:
        for sheet_name, df in excel_data.items():
            table_name = sheet_name.lower()
            
            if table_name not in existing_tables:
                logger.warning(f"Table {table_name} does not exist in database. Skipping sheet {sheet_name}")
                continue
            
            logger.info(f"Processing sheet {sheet_name} -> table {table_name}")
            
            # Map columns from Russian to English
            df_mapped = map_columns(df, sheet_name)
            
            # Insert data
            rows_inserted = insert_data_to_table(conn, table_name, df_mapped)
            total_inserted += rows_inserted
        
        logger.info(f"Import completed successfully. Total rows inserted: {total_inserted}")
        
    except Exception as e:
        logger.error(f"Error during import process: {e}")
        raise
    finally:
        conn.close()

if __name__ == "__main__":
    main()
