import os
import sys
import pandas as pd
import psycopg2
from psycopg2 import sql
from psycopg2.extras import RealDictCursor
from dotenv import load_dotenv
from datetime import datetime
import logging

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('excel_import.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Database configuration
DATABASE_HOST = os.getenv("DATABASE_HOST", "localhost")
DATABASE_PORT = int(os.getenv("DATABASE_PORT", "5432"))
DATABASE_NAME = os.getenv("DATABASE_NAME", "power_bi_bot")
DATABASE_USER = os.getenv("DATABASE_USER", "bot_user")
DATABASE_PASSWORD = os.getenv("DATABASE_PASSWORD", "bot_password")

# Excel file path
EXCEL_FILE_PATH = "Data_DM (3).xlsx"

# Column mapping from Russian (Excel) to English (Database)
# This mapping will need to be adjusted based on actual Excel column names
COLUMN_MAPPINGS = {
    'P1': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ð Ð¾Ð»ÑŒ': 'edu_role',
        'Ð¢Ð¸Ð¿ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹  Ð¶Ð°Ð»Ð¾Ð±Ð°': 'edu_problem',
        'ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¶Ð°Ð»Ð¾Ð±Ð°': 'edu_describtion',
        'ÐŸÑ€Ð¸Ð½ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ€Ñ‹_Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ_Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°': 'edu_contact'
    },
    'P2': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ð Ð¾Ð»ÑŒ': 'edu_role',
        'Ð¡Ñ„ÐµÑ€Ð° Ð¸Ð´ÐµÐ¸': 'edu_sphere',
        'ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚': 'edu_result',
        'ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð´ÐµÐ¸': 'edu_describtion',
        'ÐÐ²Ñ‚Ð¾Ñ€ Ð¸Ð´ÐµÐ¸': 'edu_author',
        'ÐŸÑ€Ð¸Ð½ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ€Ñ‹_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_contact'
    },
    'P3': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'ðŸ™‚\xa0Ð­Ð¼Ð¾Ñ†Ð¸ÑÐ»Ñ‹Ò› Ð¶Ð°Ò“Ð´Ð°Ð¹ / Ð­Ð¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ': 'edu_emotional_state',
        'ðŸ¤\xa0ÒšÐ°Ò›Ñ‚Ñ‹Ò“Ñ‹ÑÑ‚Ð°Ñ€ Ð¶Ó™Ð½Ðµ Ò›Ð°Ñ€Ñ‹Ð¼-Ò›Ð°Ñ‚Ñ‹Ð½Ð°ÑÑ‚Ð°Ñ€ / ÐšÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚Ñ‹ Ð¸ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ñ': 'edu_conflicts_relations',
        'ðŸš«\xa0Ð‘ÑƒÐ»Ð»Ð¸Ð½Ð³ / ÐºÐ¸Ð±ÐµÑ€Ð±ÑƒÐ»Ð»Ð¸Ð½Ð³': 'edu_bullying_cyberbullying',
        'ðŸ“–\xa0ÐžÒ›ÑƒÐ´Ð°Ò“Ñ‹ Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€ / ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð² Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ð¸': 'edu_learning_problems',
        'âš ï¸\xa0Ð”Ð°Ò“Ð´Ð°Ñ€Ñ‹ÑÑ‚Ñ‹Ò› Ð¶Ð°Ò“Ð´Ð°Ð¹Ð»Ð°Ñ€ / ÐšÑ€Ð¸Ð·Ð¸ÑÐ½Ñ‹Ðµ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸Ð¸': 'edu_crisis_situations',
        'ðŸ’¬\xa0ÐŸÑ€Ð¾Ñ„Ð¸Ð»Ð°ÐºÑ‚Ð¸ÐºÐ°Ð»Ñ‹Ò› Ó™Ò£Ð³Ñ–Ð¼Ðµ / ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ñ / ÐŸÑ€Ð¾Ñ„Ð¸Ð»Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð±ÐµÑÐµÐ´Ð° / ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ñ': 'edu_preventive_consultation',
        'ðŸ“Œ\xa0Ð‘Ð°ÑÒ›Ð° / ÐŸÑ€Ð¾Ñ‡ÐµÐµ': 'edu_other',
        'Ð‘Ð°Ñ€Ð»Ñ‹Ò“Ñ‹_Ð¿ÑÐ¸Ñ…Ð¾Ð»Ð¾Ð³': 'edu_total_psychologist',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_contact'
    },
    'Q1': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ð Ð¾Ð»ÑŒ': 'edu_role',
        'Ð¢Ð¸Ð¿ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹_Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ': 'edu_problem',
        'Ð¡Ñ‹Ð½Ñ‹Ð¿_Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ': 'edu_grate',
        'Ð›Ð¸Ñ‚ÐµÑ€ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ': 'edu_litter',
        'ÐŸÑ€ÐµÐ´Ð¼ÐµÑ‚_Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ': 'edu_subject',
        'Ð”Ð°Ñ‚Ð°_Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ': 'edu_problem_date',
        'ÐŸÑ€Ð¸Ð½ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ€Ñ‹_Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ_Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ': 'edu_contact'
    },
    'Q2': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ð Ð¾Ð»ÑŒ': 'edu_role',
        'Ð¢Ð¸Ð¿ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚': 'edu_problem',
        'ÐŸÑ€ÐµÐ´Ð¼ÐµÑ‚_Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚': 'edu_subject',
        'Ð¡Ñ‹Ð½Ñ‹Ð¿ Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚': 'edu_grate',
        'Ð›Ð¸Ñ‚ÐµÑ€ Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚': 'edu_litter',
        'ÐŸÑ€Ð¸Ð½ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ€Ñ‹_Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ_Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚': 'edu_contact'
    },
    'Q3': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ð Ð¾Ð»ÑŒ': 'edu_role',
        'Ð¢Ð¸Ð¿ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°': 'edu_problem',
        'Ð¤Ð˜Ðž ÑƒÑ‡Ð°Ñ‰Ð¸Ñ…ÑÑ_Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°': 'edu_full_name',
        'Ð¡Ñ‹Ð½Ñ‹Ð¿ Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°': 'edu_grate',
        'Ð›Ð¸Ñ‚ÐµÑ€ Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°': 'edu_litter',
        'ÐŸÑ€Ð¸Ð½ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ€Ñ‹_Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ_Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°': 'edu_contact'
    },
    'Q4': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ð Ð¾Ð»ÑŒ': 'edu_role',
        'ÐÐ¾Ð¼ÐµÑ€ ÐºÐ°Ð±Ð¸Ð½ÐµÑ‚Ð°': 'edu_problem',  # Mapping room number to problem field
        'Ð¢Ð¸Ð¿ ÑÐ±Ð¾Ñ': None,  # Skip this - no good mapping
        'ÐŸÑ€Ð¸Ð½ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ€Ñ‹_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_contact'
    },
    'Q5': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'ðŸ‘¥ Ð‘Ð°Ñ€Ð»Ñ‹Ò“Ñ‹ / Ð’ÑÐµÐ³Ð¾ ÑƒÑ‡Ð¸Ñ‚ÐµÐ»ÐµÐ¹': 'edu_total_teachers',
        'ðŸ¤’ ÐÑƒÑ‹Ñ€Ò“Ð°Ð½Ñ‹Ð½Ð° Ð±Ð°Ð¹Ð»Ð°Ð½Ñ‹ÑÑ‚Ñ‹ / ÐŸÐ¾ Ð±Ð¾Ð»ÐµÐ·Ð½Ð¸': 'edu_illness',
        'âœˆï¸ Ð†ÑÑÐ°Ð¿Ð°Ñ€ / ÐšÐ¾Ð¼Ð°Ð½Ð´Ð¸Ñ€Ð¾Ð²ÐºÐ°': 'edu_business_trip',
        'ðŸ  Ð–ÐµÐºÐµ ÑÐµÐ±ÐµÐ¿Ñ‚ÐµÑ€ / Ð›Ð¸Ñ‡Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ñ‹': 'edu_personal_reasons',
        'ðŸŽ“ Ð‘Ñ–Ð»Ñ–ÐºÑ‚Ñ–Ð»Ñ–ÐºÑ‚Ñ– Ð°Ñ€Ñ‚Ñ‚Ñ‹Ñ€Ñƒ / ÐŸÐ¾Ð²Ñ‹ÑˆÐµÐ½Ð¸Ðµ ÐºÐ²Ð°Ð»Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸': 'edu_professional_development',
        'ðŸ“Œ Ð‘Ð°ÑÒ›Ð° / ÐŸÑ€Ð¾Ñ‡ÐµÐµ': 'edu_other',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_contact'
    },
    'S1': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ñ€Ð¾Ð»ÑŒ': 'edu_role',
        'ÐžÑÐ¼Ð¾Ñ‚Ñ€ÐµÐ½Ð¾ ÐºÐ°Ð±Ð¸Ð½ÐµÑ‚Ð¾Ð²': 'edu_class_num',
        'Ð­Ñ‚Ð°Ð¶': 'edu_floor',
        'ÐšÐ°Ð±Ð¸Ð½ÐµÑ‚': 'edu_classroom',
        'ÐžÑ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¸Ðµ': 'edu_problem',
        'Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ ÐºÐ°Ð±Ð¸Ð½ÐµÑ‚Ð°': 'edu_condition',
        'Ð”ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐšÐµÑ€Ñ– Ð±Ð°Ð¹Ð»Ð°Ð½Ñ‹Ñ': 'edu_contact'
    },
    'S2': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ð Ð¾Ð»ÑŒ': 'edu_role',
        'ÐžÑÐ¼Ð¾Ñ‚Ñ€ÐµÐ½Ð¾ Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¹': 'edu_loc_num',
        'Ð›Ð¾ÐºÐ°Ñ†Ð¸Ñ_Ð§Ð¨': 'edu_location',
        'Ð­Ñ‚Ð°Ð¶_Ð§Ð¨': 'edu_floor',
        'ÐœÐµÑÑ‚Ð¾_Ð§Ð¨': 'edu_place',
        'Ð¢Ð¸Ð¿ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹_Ð§Ð¨': 'edu_problem',
        'Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ_Ð§Ð¨': 'edu_condition',
        'ÐŸÑ€Ð¸Ð½ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ€Ñ‹_Ð§Ð¨': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ_Ð§Ð¨': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð§Ð¨': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…_Ð§Ð¨': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð§Ð¨': 'edu_contact'
    },
    'S3': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ð Ð¾Ð»ÑŒ': 'edu_role',
        'ÐžÑÐ¼Ð¾Ñ‚Ñ€ÐµÐ½Ð¾ Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¹': 'edu_loc_num',
        'Ð›Ð¾ÐºÐ°Ñ†Ð¸Ñ_Ð¢Ð ': 'edu_location',
        'Ð­Ñ‚Ð°Ð¶_Ð¢Ð ': 'edu_floor',
        'ÐœÐµÑÑ‚Ð¾_Ð¢Ð ': 'edu_place',
        'Ð¢Ð¸Ð¿ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹_Ð¢Ð ': 'edu_problem',
        'Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ_Ð¢Ð ': 'edu_condition',
        'ÐŸÑ€Ð¸Ð½ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ€Ñ‹_Ð¢Ð ': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ_Ð¢Ð ': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð¢Ð ': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…_Ð¢Ð ': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð¢Ð ': 'edu_contact'
    },
    'S4': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ñ€Ð¾Ð»ÑŒ': 'edu_role',
        'Ð¢Ð¸Ð¿ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹': 'edu_problem',
        'ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ Ñ€Ð¸ÑÐºÐ°': 'edu_condition',
        'ÐŸÑ€Ð¸Ð½ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ€Ñ‹': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸': 'edu_contact'
    },
    'S5': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ð Ð¾Ð»ÑŒ': 'edu_role',
        'Ð˜Ð½Ñ†Ð¸Ð´ÐµÐ½Ñ‚': 'edu_incident',
        'ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð½Ñ†Ð¸Ð´ÐµÐ½Ñ‚': 'edu_describtion',
        'ÐŸÑ€Ð¸Ð½ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ€Ñ‹_Ð¸Ð½Ñ†Ð¸Ð´ÐµÐ½Ñ‚': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ_Ð¸Ð½Ñ†Ð¸Ð´ÐµÐ½Ñ‚': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð¸Ð½Ñ†Ð¸Ð´ÐµÐ½Ñ‚': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð¸Ð½Ñ†Ð¸Ð´ÐµÐ½Ñ‚': 'edu_contact'
    },
    'S6': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ð Ð¾Ð»ÑŒ': 'edu_role',
        'ÐžÑ…Ñ€Ð°Ð½Ð°': 'edu_security',
        'ÐŸÑ€Ð¸Ð½ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ€Ñ‹_Ð¾Ñ…Ñ€Ð°Ð½Ð°': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ_Ð¾Ñ…Ñ€Ð°Ð½Ð°': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð¾Ñ…Ñ€Ð°Ð½Ð°': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð¾Ñ…Ñ€Ð°Ð½Ð°': 'edu_contact'
    },
    'S7': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'Ð Ð¾Ð»ÑŒ': 'edu_role',
        'Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_problem',
        'ÐŸÑ€Ð¸Ð½ÑÑ‚Ñ‹Ðµ Ð¼ÐµÑ€Ñ‹_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_action',
        'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_status',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_contact'
    },
    'S8': {
        'ID': 'id',
        'ÐœÐµÐºÑ‚ÐµÐ¿': 'edu_school',
        'Ð”Ð°Ñ‚Ð°': 'edu_date',
        'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ…Ð¾Ð´Ð°': 'edu_time',
        'ðŸ½ ÐÑ Ò›Ð¾Ñ€Ñ‹Ñ‚Ñƒ Ð¶Ò¯Ð¹ÐµÑÑ– / Ð–ÐšÐ¢ (Ð¿Ð¸Ñ‰ÐµÐ²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð°)': 'edu_digestive_system',
        'Ð¢Ò±Ð¼Ð°Ñƒ / ÐžÐ Ð’Ð˜ Ð¸ Ð¿Ñ€Ð¾ÑÑ‚ÑƒÐ´Ð½Ñ‹Ðµ Ð·Ð°Ð±Ð¾Ð»ÐµÐ²Ð°Ð½Ð¸Ñ': 'edu_cold_flu',
        'ðŸ¤• Ð–Ð°Ñ€Ð°Ò›Ð°Ñ‚Ñ‚Ð°Ñ€ / Ð¢Ñ€Ð°Ð²Ð¼Ñ‹': 'edu_injuries',
        'ðŸŒ¸ ÐÐ»Ð»ÐµÑ€Ð³Ð¸ÑÐ»Ñ‹Ò› Ñ€ÐµÐ°ÐºÑ†Ð¸ÑÐ»Ð°Ñ€ / ÐÐ»Ð»ÐµÑ€Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ€ÐµÐ°ÐºÑ†Ð¸Ð¸': 'edu_allergic_reactions',
        'ðŸ§  ÐÐµÐ²Ñ€Ð¾Ð»Ð¾Ð³Ð¸ÑÐ»Ñ‹Ò› Ð¶Ó™Ð½Ðµ Ð¶Ð°Ð»Ð¿Ñ‹ Ð¶Ð°Ò“Ð´Ð°Ð¹ / ÐÐµÐ²Ñ€Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸ Ð¾Ð±Ñ‰ÐµÐµ ÑÐ°Ð¼Ð¾Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ðµ': 'edu_neurological_general',
        'â™»ï¸ Ð¡Ð¾Ð·Ñ‹Ð»Ð¼Ð°Ð»Ñ‹ Ð°ÑƒÑ€ÑƒÐ»Ð°Ñ€Ð´Ñ‹Ò£ Ð°ÑÒ›Ñ‹Ð½ÑƒÑ‹ / ÐžÐ±Ð¾ÑÑ‚Ñ€ÐµÐ½Ð¸Ðµ Ñ…Ñ€Ð¾Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð·Ð°Ð±Ð¾Ð»ÐµÐ²Ð°Ð½Ð¸Ð¹': 'edu_chronic_diseases',
        'ðŸ“Œ Ð‘Ð°ÑÒ›Ð° / ÐŸÑ€Ð¾Ñ‡ÐµÐµ': 'edu_other',
        'Ð‘Ð°Ñ€Ð»Ñ‹Ò“Ñ‹_Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½Ð°': 'edu_total_medical',
        'Ð¤Ð¾Ñ‚Ð¾/ÑÑÑ‹Ð»ÐºÐ°_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_photo',
        'Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…': 'edu_data_from',
        'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ (ÑÑŽÐ´Ð° Ð²Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€ÑŒ)': 'edu_add_inf',
        'ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸_Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ': 'edu_contact'
    }
}

def get_database_connection():
    """Establish connection to PostgreSQL database."""
    try:
        connection = psycopg2.connect(
            host=DATABASE_HOST,
            port=DATABASE_PORT,
            database=DATABASE_NAME,
            user=DATABASE_USER,
            password=DATABASE_PASSWORD
        )
        return connection
    except Exception as e:
        logger.error(f"Error connecting to database: {e}")
        raise

def test_database_connection():
    """Test database connection and show basic info."""
    try:
        conn = get_database_connection()
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        
        # Test connection
        cursor.execute("SELECT version();")
        version = cursor.fetchone()
        if version:
            logger.info(f"PostgreSQL version: {version['version']}")
        else:
            logger.info("Connected to PostgreSQL database")
        
        # Check if tables exist
        cursor.execute("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'dbo' 
            AND table_name IN ('p1', 'p2', 'p3', 'q1', 'q2', 'q3', 'q4', 'q5', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8')
            ORDER BY table_name;
        """)
        
        tables = cursor.fetchall()
        table_names = [table['table_name'] for table in tables]
        logger.info(f"Found tables: {table_names}")
        
        cursor.close()
        conn.close()
        
        return True, table_names
    except Exception as e:
        logger.error(f"Database connection test failed: {e}")
        return False, []

def read_excel_file(file_path):
    """Read Excel file and return dictionary of DataFrames for each sheet."""
    try:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Excel file not found: {file_path}")
        
        # Read all sheets
        excel_data = pd.read_excel(file_path, sheet_name=None, engine='openpyxl')
        
        # Filter only the sheets we need
        target_sheets = ['P1', 'P2', 'P3', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8']
        filtered_data = {}
        
        for sheet_name in target_sheets:
            if sheet_name in excel_data:
                df = excel_data[sheet_name]
                if not df.empty:
                    filtered_data[sheet_name] = df
                    logger.info(f"Sheet {sheet_name}: {len(df)} rows, {len(df.columns)} columns")
                else:
                    logger.warning(f"Sheet {sheet_name} is empty")
            else:
                logger.warning(f"Sheet {sheet_name} not found in Excel file")
        
        return filtered_data
    except Exception as e:
        logger.error(f"Error reading Excel file: {e}")
        raise

def map_columns(df, sheet_name):
    """Map Russian column names to English database column names."""
    if sheet_name not in COLUMN_MAPPINGS:
        logger.warning(f"No column mapping found for sheet {sheet_name}")
        return df
    
    mapping = COLUMN_MAPPINGS[sheet_name]
    
    # Create a mapping dictionary for actual columns that exist in the DataFrame
    actual_mapping = {}
    for russian_col, english_col in mapping.items():
        if english_col is None:  # Skip columns that have no database equivalent
            continue
        if russian_col in df.columns:
            actual_mapping[russian_col] = english_col
        else:
            # Try to find similar column names (case insensitive, strip whitespace)
            for col in df.columns:
                if str(col).strip().lower() == russian_col.lower():
                    actual_mapping[col] = english_col
                    break
    
    # Debug: Print column mapping details for P3
    if sheet_name == 'P3':
        logger.info(f"P3 Debug - Excel columns: {list(df.columns)}")
        logger.info(f"P3 Debug - Mapping attempted: {list(mapping.keys())}")
        logger.info(f"P3 Debug - Successful mappings: {actual_mapping}")
        
        # Check specific emoji columns
        emoji_cols = [col for col in df.columns if any(emoji in str(col) for emoji in ['ðŸ™‚', 'ðŸ¤', 'ðŸš«', 'ðŸ“–', 'âš ï¸', 'ðŸ’¬', 'ðŸ“Œ'])]
        logger.info(f"P3 Debug - Emoji columns found: {emoji_cols}")
        
        for col in emoji_cols:
            if col in df.columns:
                logger.info(f"P3 Debug - Column '{col}' sample data: {df[col].head(3).tolist()}")
    
    # Rename columns
    df_mapped = df.rename(columns=actual_mapping)
    
    # Add default values for missing columns
    if 'edu_data_from' not in df_mapped.columns:
        df_mapped['edu_data_from'] = 'Excel Import'
    
    logger.info(f"Sheet {sheet_name}: Mapped {len(actual_mapping)} columns")
    logger.debug(f"Column mapping for {sheet_name}: {actual_mapping}")
    
    return df_mapped

def clean_data(df):
    """Clean and prepare data for database insertion."""
    import datetime
    
    # Make a copy to avoid modifying the original
    df = df.copy()
    
    # Convert datetime columns
    for col in df.columns:
        if 'date' in col.lower():
            if df[col].dtype == 'object' or 'datetime' in str(df[col].dtype):
                # Check if values are already date objects
                sample_non_null = df[col].dropna()
                if len(sample_non_null) > 0 and isinstance(sample_non_null.iloc[0], datetime.date):
                    # Already date objects, just replace NaN with None
                    df[col] = df[col].where(pd.notnull(df[col]), None)
                else:
                    df[col] = pd.to_datetime(df[col], errors='coerce').dt.date
                    # Replace NaT with None
                    df[col] = df[col].where(pd.notnull(df[col]), None)
        elif 'time' in col.lower() and col != 'created_at':
            # Check if values are already time objects
            sample_non_null = df[col].dropna()
            if len(sample_non_null) > 0:
                first_val = sample_non_null.iloc[0]
                if isinstance(first_val, datetime.time):  # Already a time object
                    # Just replace NaT/NaN with None
                    df[col] = df[col].where(pd.notnull(df[col]), None)
                else:
                    # Convert to time
                    if df[col].dtype == 'object' or 'datetime' in str(df[col].dtype):
                        df[col] = pd.to_datetime(df[col], errors='coerce').dt.time
                        # Replace NaT with None
                        df[col] = df[col].where(pd.notnull(df[col]), None)
    
    # Replace all remaining NaN/NaT values with None
    df = df.where(pd.notnull(df), None)
    
    return df

def insert_data_to_table(conn, table_name, df):
    """Insert DataFrame data into specified table."""
    if df.empty:
        logger.info(f"No data to insert for table {table_name}")
        return 0
    
    try:
        cursor = conn.cursor()
        
        # Get table columns from database
        cursor.execute(sql.SQL("""
            SELECT column_name 
            FROM information_schema.columns 
            WHERE table_schema = 'dbo' 
            AND table_name = %s 
            AND column_name != 'id' 
            AND column_name != 'created_at'
            ORDER BY ordinal_position;
        """), [table_name])
        
        db_columns = [row[0] for row in cursor.fetchall()]
        
        # Filter DataFrame columns to match database columns
        available_columns = [col for col in db_columns if col in df.columns]
        
        if not available_columns:
            logger.warning(f"No matching columns found for table {table_name}")
            return 0
        
        # Prepare data for insertion
        df_filtered = df[available_columns].copy()
        df_filtered = clean_data(df_filtered)
        
        # Additional cleaning for problematic values
        for col in df_filtered.columns:
            try:
                if df_filtered[col].dtype == 'object':
                    # Replace any string representations of NaT or NaN
                    df_filtered[col] = df_filtered[col].replace(['NaT', 'NaN', 'nat', 'nan'], None)
            except Exception as e:
                logger.debug(f"Could not process column {col}: {e}")
                continue
        
        logger.debug(f"Data types for {table_name}: {df_filtered.dtypes.to_dict()}")
        logger.debug(f"Sample data for {table_name}: {df_filtered.head(2).to_dict()}")
        
        # Create INSERT query
        columns_sql = sql.SQL(', ').join(sql.Identifier(col) for col in available_columns)
        placeholders = sql.SQL(', ').join(sql.Placeholder() * len(available_columns))
        
        insert_query = sql.SQL("""
            INSERT INTO dbo.{table} ({columns}) 
            VALUES ({placeholders})
        """).format(
            table=sql.Identifier(table_name),
            columns=columns_sql,
            placeholders=placeholders
        )
        
        # Convert DataFrame to list of tuples, ensuring no pandas objects
        data_tuples = []
        for _, row in df_filtered.iterrows():
            row_tuple = []
            for value in row:
                if pd.isna(value) or str(value) in ['NaT', 'NaN', 'nat', 'nan']:
                    row_tuple.append(None)
                else:
                    # Truncate text that's too long for database fields
                    if isinstance(value, str) and len(value) > 500:
                        logger.warning(f"Truncating long text in {table_name}: {value[:50]}...")
                        value = value[:500]
                    row_tuple.append(value)
            data_tuples.append(tuple(row_tuple))
        
        # Execute batch insert
        cursor.executemany(insert_query, data_tuples)
        rows_inserted = cursor.rowcount
        
        conn.commit()
        cursor.close()
        
        logger.info(f"Successfully inserted {rows_inserted} rows into table {table_name}")
        return rows_inserted
        
    except Exception as e:
        logger.error(f"Error inserting data into table {table_name}: {e}")
        conn.rollback()
        raise

def main():
    """Main function to execute the Excel to PostgreSQL import."""
    logger.info("Starting Excel to PostgreSQL import process")
    
    # Test database connection
    logger.info("Testing database connection...")
    connection_ok, existing_tables = test_database_connection()
    
    if not connection_ok:
        logger.error("Database connection failed. Exiting.")
        sys.exit(1)
    
    # Read Excel file
    logger.info(f"Reading Excel file: {EXCEL_FILE_PATH}")
    try:
        excel_data = read_excel_file(EXCEL_FILE_PATH)
    except Exception as e:
        logger.error(f"Failed to read Excel file: {e}")
        sys.exit(1)
    
    if not excel_data:
        logger.error("No valid sheets found in Excel file")
        sys.exit(1)
    
    # Process each sheet
    total_inserted = 0
    conn = get_database_connection()
    
    try:
        for sheet_name, df in excel_data.items():
            table_name = sheet_name.lower()
            
            if table_name not in existing_tables:
                logger.warning(f"Table {table_name} does not exist in database. Skipping sheet {sheet_name}")
                continue
            
            logger.info(f"Processing sheet {sheet_name} -> table {table_name}")
            
            # Map columns from Russian to English
            df_mapped = map_columns(df, sheet_name)
            
            # Insert data
            rows_inserted = insert_data_to_table(conn, table_name, df_mapped)
            total_inserted += rows_inserted
        
        logger.info(f"Import completed successfully. Total rows inserted: {total_inserted}")
        
    except Exception as e:
        logger.error(f"Error during import process: {e}")
        raise
    finally:
        conn.close()

if __name__ == "__main__":
    main()
